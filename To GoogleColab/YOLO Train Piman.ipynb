{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO Train Piman.ipynb","version":"0.3.2","provenance":[{"file_id":"1pgGlqF_e1lMeJtPKQo00fx2CWVr8SEpt","timestamp":1561865732068}],"collapsed_sections":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EkHlas4lf15A","colab_type":"code","colab":{}},"source":["# Google ドライブをマウントするには、このセルを実行してください。\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0H9UOWRA421","colab_type":"code","colab":{}},"source":["g_drive = 'drive/My Drive/Colab Notebooks/Piman2/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XknwclhofNX0","colab_type":"code","colab":{}},"source":["# グーグルドライブから必要なファイルを取得\n","# 画像も取得しているのはv3の時にエラーが出ため、このコードだと必要ないのかも\n","import shutil\n","import glob\n","import os\n","shutil.copyfile(g_drive + \"model_data/utils.py\", \"./utils.py\")\n","shutil.copyfile(g_drive + \"model_data/keras_yolo.py\", \"./keras_yolo.py\")\n","shutil.copyfile(g_drive + \"model_data/keras_darknet19.py\", \"./keras_darknet19.py\")\n","shutil.copyfile(g_drive + \"model_data/yolo_utils.py\", \"./yolo_utils.py\")\n","shutil.copyfile(g_drive + \"model_data/FiraMono-Medium.otf\", \"./FiraMono-Medium.otf\")\n","\n","files = glob.glob(g_drive + \"images/*\")\n","os.mkdir(\"./images\")\n","for file in files:\n","     shutil.copyfile(file, \"./images/\" + os.path.basename(file))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XpkLEm7AA42q","colab_type":"code","colab":{}},"source":["import argparse\n","import os\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","import scipy.io\n","import scipy.misc\n","import numpy as np\n","import pandas as pd\n","import PIL\n","from PIL import Image, ImageDraw, ImageFont\n","import time\n","import cv2\n","\n","import tensorflow as tf\n","from keras import backend as K\n","from keras.layers import Input, Lambda, Conv2D\n","from keras.models import load_model, Model\n","from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n","from keras_yolo import yolo_head, yolo_eval, preprocess_true_boxes, yolo_loss, yolo_body,tiny_yolo_body\n","\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import Model\n","from keras.regularizers import l2\n","from keras.optimizers import SGD, Adam"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yU89gwusbCoi","colab_type":"code","colab":{}},"source":["tf.test.gpu_device_name()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1UPbFgDA425","colab_type":"code","colab":{}},"source":["#YOLO モデルの設定\n","image_size = 384\n","dataname = 'Piman'\n","class_names = [dataname]\n","YOLO_ANCHORS = np.array(\n","    ((0.57273, 0.677385), (1.87446, 2.06253), (3.33843, 5.47434),\n","     (7.88282, 3.52778), (9.77052, 9.16828)))\n","anchors = YOLO_ANCHORS"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fc8X4PdaA429","colab_type":"text"},"source":["## load images"]},{"cell_type":"code","metadata":{"id":"EeTPLIxurDX1","colab_type":"code","colab":{}},"source":["xml_df = pd.read_csv(g_drive + '/labels.csv')\n","fileName = np.sort(xml_df[\"filename\"].unique())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ndreMnApA42-","colab_type":"code","colab":{}},"source":["images_dir = g_drive + '/images/'\n","images_f = open(g_drive + '/labels.csv','r')\n","images = []\n","images_cv = []\n","count = 0\n","\n","for fn in fileName:\n","      img = cv2.imread(images_dir+fn)\n","      orig_size = np.array([img.shape[1], img.shape[0]])\n","      img = cv2.resize(img, (image_size,image_size), interpolation=cv2.INTER_CUBIC)\n","      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","      image_data = np.array(img, dtype=np.float)\n","      image_data /= 255.\n","      images.append(image_data)\n","      images_cv.append(img)\n","    \n","images_f.close()\n","orig_size = np.expand_dims(orig_size, axis=0)\n","print (orig_size)\n","images = np.asarray(images)\n","print(images.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vj0iITTrA43E","colab_type":"text"},"source":["## load labels"]},{"cell_type":"code","metadata":{"id":"IEsGaqo-A43G","colab_type":"code","colab":{}},"source":["# Load Labels\n","labels_path = g_drive + '/labels.csv'\n","labels_f = open(labels_path,'r')\n","boxes = []\n","detectors_mask_list = []\n","matching_true_boxes_list = []\n","\n","\n","textAry = []\n","for fn in fileName:\n","  count = 0\n","  textLine = 'images/' + fn\n","  tempDf = xml_df[xml_df['filename'] == fn]\n","  for index, d in tempDf.iterrows():\n","    textLine =  (\"%s %d,%d,%d,%d,0\" % (textLine, d.xmin, d.xmax, d.ymin, d.ymax))\n","    #print(textLine)\n","    box_xy = [[(float(d.xmax) + float(d.xmin))*0.5,(float(d.ymax) + float(d.ymin))*0.5]]\n","    box_wh = [[(float(d.xmax) - float(d.xmin)),(float(d.ymax) - float(d.ymin))]]\n","    box_xy = box_xy / ((orig_size)*1.0)\n","    box_wh = box_wh / ((orig_size)*1.0)\n","    if count==0:\n","      box = np.concatenate((box_xy, box_wh, np.array([[1]])), axis=1)\n","    else:\n","      box = np.append(box, np.concatenate((box_xy, box_wh, np.array([[1]])), axis=1), axis=0)\n","    count = count + 1\n","  if len(box) < 10:\n","      box = np.append(box, np.zeros((10-len(box), 5)), axis=0)\n","  boxes.append(box)\n","  #print(box.shape)\n","  detectors_mask, matching_true_boxes = preprocess_true_boxes(box, anchors, [image_size, image_size])\n","  detectors_mask_list.append(detectors_mask)\n","  matching_true_boxes_list.append(matching_true_boxes)\n","    \n","# Precompute detectors_mask and matching_true_boxes for training.\n","# Detectors mask is 1 for each spatial position in the final conv layer and\n","# anchor that should be active for the given boxes and 0 otherwise.\n","# Matching true boxes gives the regression targets for the ground truth box\n","# that caused a detector to be active or 0 otherwise.\n","detectors_mask_shape = np.asarray(detectors_mask_list[0]).shape\n","matching_boxes_shape = np.asarray(matching_true_boxes_list[0]).shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XkJ0d-WnJeM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NmC2-7bJA43R","colab_type":"text"},"source":["## Define Model"]},{"cell_type":"code","metadata":{"id":"FGLEqBq6A43T","colab_type":"code","colab":{}},"source":["# Create model input layers.\n","image_input = Input(shape=(image_size, image_size, 3))\n","boxes_input = Input(shape=(None, 5))\n","detectors_mask_input = Input(shape=detectors_mask_shape)\n","matching_boxes_input = Input(shape=matching_boxes_shape)\n","\n","boxes = np.asarray(boxes)\n","detectors_mask_list = np.asarray(detectors_mask_list)\n","matching_true_boxes_list = np.asarray(matching_true_boxes_list)\n","\n","\n","model_body = tiny_yolo_body(image_input, len(anchors), len(class_names))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbWQd17sA43Z","colab_type":"code","colab":{}},"source":["with tf.device('/cpu:0'):\n","    # TODO: Replace Lambda with custom Keras layer for loss.\n","    model_loss = Lambda(\n","        yolo_loss,\n","        output_shape=(1, ),\n","        name='yolo_loss',\n","        arguments={'anchors': anchors,\n","                   'num_classes': len(class_names),\n","                   'print_loss': True})([\n","                       model_body.output, \n","                       boxes_input,\n","                       detectors_mask_input, \n","                       matching_boxes_input\n","                   ])\n","model = Model(\n","    [image_input, boxes_input, detectors_mask_input,\n","     matching_boxes_input], model_loss)\n","sgd = SGD(lr=0.0000005, decay=0.0005, momentum=0.9)\n","adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(optimizer=adam, \n","              loss={\n","                  'yolo_loss': lambda y_true, y_pred: y_pred\n","              })  # This is a hack to use the custom loss function in the last layer.\n","#model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WyPd-xaIA43c","colab_type":"code","colab":{}},"source":["\n","num_steps = 100\n","# TODO: For full training, put preprocessing inside training loop.\n","#for i in range(num_steps):\n","#     loss = model.train_on_batch(\n","#         [image_data, boxes, detectors_mask, matching_true_boxes],\n","#         np.zeros(len(image_data)))\n","\n","#model.load_weights(g_drive + 'tiny_weights.h5')\n","model.fit([images, boxes, detectors_mask_list, matching_true_boxes_list],\n","          np.zeros(len(images)),\n","          batch_size=1,\n","          epochs=num_steps)\n","model.save_weights(g_drive + 'tiny_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIOpjwG3A43l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}